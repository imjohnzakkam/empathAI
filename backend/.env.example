# EmpathAI LLM Configuration

# Select which LLM provider to use (options: openai, huggingface, ollama, together_ai, google, anthropic)
# Leave empty to use template-based responses
LLM_PROVIDER=

# Specify the model to use for the selected provider
# If left empty, a default model will be used
# Examples:
# - OpenAI: gpt-3.5-turbo, gpt-4
# - HuggingFace: mistralai/Mistral-7B-Instruct-v0.2
# - Ollama: llama2, mistral
# - Together.ai: mistralai/Mistral-7B-Instruct-v0.2, togethercomputer/RedPajama-INCITE-7B-Instruct
# - Google: gemini-pro
# - Anthropic: claude-3-sonnet-20240229
LLM_MODEL=

# API Keys for different providers
# Only configure the one you're using
OPENAI_API_KEY=
HUGGINGFACE_API_KEY=
TOGETHER_AI_API_KEY=
GOOGLE_API_KEY=
ANTHROPIC_API_KEY=
DEEPSEEK_API_KEY=sk-3a28101b83cb420c99b9e4aee56909ce
# For Ollama (local deployment)
OLLAMA_API_URL=http://localhost:11434/api/generate 