# EmpathAI LLM Configuration

# Select which LLM provider to use (options: openai, huggingface, ollama, together_ai, google, anthropic, deepseek, openrouter)
# Leave empty to use template-based responses
LLM_PROVIDER=openrouter

# Specify the model to use for the selected provider
# Using Deepseek through Openrouter
LLM_MODEL=deepseek/deepseek-chat:free

# API Keys for different providers
# Only configure the one you're using

# For Openrouter:
# Replace "your_openrouter_api_key_here" with your actual Openrouter API key
# (You mentioned you already have an API key that works with the curl request)
OPENROUTER_API_KEY=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

# Keep other keys in case you want to switch back later
DEEPSEEK_API_KEY=sk-3a28101b83cb420c99b9e4aee56909ce
HUGGINGFACE_API_KEY=
OPENAI_API_KEY=
TOGETHER_AI_API_KEY=
GOOGLE_API_KEY=
ANTHROPIC_API_KEY=

# For Ollama (local deployment)
OLLAMA_API_URL=http://localhost:11434/api/generate
